{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXVUOy5UlqSd",
        "outputId": "5ea23fd7-c56f-489c-e06c-1235d994bf91"
      },
      "source": [
        "# Install the SQLAlchemy library if it is not installed\n",
        "!sudo apt-get install python3-dev libmysqlclient-dev > /dev/null\n",
        "!pip install mysqlclient > /dev/null\n",
        "!sudo pip3 install -U sql_magic > /dev/null\n",
        "!pip install psycopg2-binary > /dev/null\n",
        "!pip install polygon-api-client\n",
        "!pip install yfinance\n",
        "!pip install praw > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polygon-api-client\n",
            "  Downloading https://files.pythonhosted.org/packages/19/c0/84a48c9b3ef8b0b5d3a9ae01f90bffd719748842d5dfe23d404910734893/polygon_api_client-0.1.11-py3-none-any.whl\n",
            "Collecting websocket-client>=0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/0c/d52a2a63512a613817846d430d16a8fbe5ea56dd889e89c68facf6b91cb6/websocket_client-0.59.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from polygon-api-client) (2.23.0)\n",
            "Collecting websockets>=8.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cb/1d313fca7318f87cd7edfeb82339c20f00f24457862ba6fb455915fb8d9f/websockets-9.0.1-cp37-cp37m-manylinux2010_x86_64.whl (102kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.56.0->polygon-api-client) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->polygon-api-client) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->polygon-api-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->polygon-api-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->polygon-api-client) (1.24.3)\n",
            "Installing collected packages: websocket-client, websockets, polygon-api-client\n",
            "Successfully installed polygon-api-client-0.1.11 websocket-client-0.59.0 websockets-9.0.1\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=0f65e9e57ba14dd3afb305992e9cb27a59476e9cbede77f8e535c70428200793\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtcLa1JOrej2"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import time\n",
        "import praw\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "# Make the graphs a bit prettier, and bigger\n",
        "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])\n",
        "plt.rcParams['figure.figsize'] = (15, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO9Cva0Jre2h"
      },
      "source": [
        "from sqlalchemy import create_engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX2yvoG-rfAQ"
      },
      "source": [
        "conn_string = 'mysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "    user=\"Unnamed\", \n",
        "    password='RyMe/s67Jw4=', \n",
        "    host = 'jsedocc7.scrc.nyu.edu', \n",
        "    port=3306, \n",
        "    db='unnamed',\n",
        "    encoding = 'utf-8'\n",
        ")\n",
        "engine = create_engine(conn_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU7VNGYEPAZO",
        "outputId": "dabc39d9-4afe-4f9e-8df1-f2f994bcac26"
      },
      "source": [
        "engine.execute('CREATE DATABASE IF NOT EXISTS unnamed')\n",
        "engine.execute('USE unnamed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7f49400adc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Dwvch-7ZrlCE",
        "outputId": "271589fb-3947-447b-ed4a-2029efaa585c"
      },
      "source": [
        "# Prepare sql_magic library that enable to query to database easily.\n",
        "%reload_ext sql_magic\n",
        "%config SQL.conn_name = 'engine'\n",
        "engine.execute('DROP TABLE IF EXISTS StockSentimentData')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    require(['notebook/js/codecell'], function(codecell) {\n",
              "      // https://github.com/jupyter/notebook/issues/2453\n",
              "      codecell.CodeCell.options_default.highlight_modes['magic_text/x-sql'] = {'reg':[/^%read_sql/, /.*=\\s*%read_sql/,\n",
              "                                                                                      /^%%read_sql/]};\n",
              "      Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
              "          console.log('BBBBB');\n",
              "          Jupyter.notebook.get_cells().map(function(cell){\n",
              "              if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
              "      });\n",
              "    });\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7f493f84f850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY4hUjNrCVS0",
        "outputId": "acbf9c57-6c83-4ad9-f3ba-ba9aab9e97f8"
      },
      "source": [
        "def reddit_data(stock_nam, num_subm):\n",
        "  reddit_list = []\n",
        "  reddit = praw.Reddit(\n",
        "      client_id=\"G35gFCI_dmA9VQ\",\n",
        "      client_secret=\"Dfb4wf9ZKSsfErunvyrlq5LxIaHQvA\",\n",
        "      user_agent=\"This is J's first!\",\n",
        "  )\n",
        "  subreddit = reddit.subreddit(\"wallstreetbets\")\n",
        "  for submission in subreddit.search(stock_nam,limit=num_subm):\n",
        "      reddit_list.append(submission.title)\n",
        "  if len(reddit_list) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return reddit_list\n",
        "\n",
        "print(reddit_data(\"AAPL\", 5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[\"YOLOing my $30k house down payment on AAPL and CLOV, bank said I can't buy house for 3 months after forbearance.\", 'For the retard who said prove it for my 180k+ AAPL reverse gain, here it is. Along with my other winners.', 'Took 4K in student loans and dropped out of college last may. Bought TSLA an BA shares. Sold them for a loss and bought 1 year AAPL puts. I even bought GME over $380 lol.', 'Me checking my AAPL puts today', '$AAPL overperforms ER expectations, so call options naturally...plummet???']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5WmDXfO1CW"
      },
      "source": [
        "import datetime\n",
        "\n",
        "from polygon import RESTClient\n",
        "\n",
        "\n",
        "def ts_to_datetime(ts) -> str:\n",
        "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "\n",
        "def main(stock, start, end):\n",
        "    key = \"5tXFTr2GW77cTrgByzwl2ibeXbubesTh\"\n",
        "\n",
        "    # RESTClient can be used as a context manager to facilitate closing the underlying http session\n",
        "    # https://requests.readthedocs.io/en/master/user/advanced/#session-objects\n",
        "    with RESTClient(key) as client:\n",
        "        from_ = start\n",
        "        to = end\n",
        "        resp = client.stocks_equities_aggregates(stock, 1, \"day\", from_, to, unadjusted=False)\n",
        "\n",
        "        #print(f\"Minute aggregates for {resp.ticker} between {from_} and {to}.\")\n",
        "        diff_chart = []\n",
        "        for result in resp.results:\n",
        "            dt = ts_to_datetime(result[\"t\"])\n",
        "            diff = result['c'] - result['o']\n",
        "            diff_chart.append(diff)\n",
        "            #print(f\"{dt}\\n\\tO: {result['o']}\\n\\tH: {result['h']}\\n\\tL: {result['l']}\\n\\tC: {result['c']} \")\n",
        "    return diff_chart\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrVssplJH4gk"
      },
      "source": [
        "payload = \"\"\n",
        "headers = {\n",
        "  'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOJVOAEAAAAAym0fsraKQD39gqqRzcG8n9mqffA%3D3MSxBpEwrMHl08PAAjNxIjy0AM8di31I9U7XXhIxT3WRgskHRM',\n",
        "  'Cookie': 'guest_id=v1%3A161903049706096483; personalization_id=\"v1_4qcst6G485Yljpwma4VR3Q==\"'\n",
        "}\n",
        "def search(query, start, end, max):\n",
        "  starttime= str(start) + \"T00:00:00Z\" #format :yr-mm-dd\n",
        "  endtime = str(end) + \"T00:00:00Z\" #format :yr-mm-dd, results are given in reverse chronological\n",
        "  maxresults = str(max)\n",
        "  url = \"https://api.twitter.com/2/tweets/search/recent?query=\" + query + \"&start_time=\" + starttime + \"&end_time=\" + endtime + \"&max_results=\" + maxresults\n",
        "  response = requests.get(url, headers=headers, data=payload)\n",
        "  tweets = response.json()\n",
        "  data = []\n",
        "  if \"data\" in tweets:\n",
        "    for i in range(len(tweets['data'])):\n",
        "      data.append(tweets['data'][i]['text'])\n",
        "    return data\n",
        "  else:\n",
        "    return None\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnUH6-8p0nN"
      },
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def yfinance_data(stock_name , num_days):\n",
        "  diff_list = []\n",
        "  stock = yf.Ticker(stock_name)\n",
        "  stock_df = stock.history(period=\"max\").tail(num_days)\n",
        "  for i in range(len(stock_df)):\n",
        "    diff = stock_df[\"Close\"][i] - stock_df[\"Open\"][i]\n",
        "    diff_list.append(diff)\n",
        "  return diff_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP05HZRpLc7I"
      },
      "source": [
        "def getSentiment(text):\n",
        "  import requests\n",
        "  import json\n",
        "  try:\n",
        "    sent = SentimentIntensityAnalyzer(text)\n",
        "    return sent[\"compound\"]\n",
        "  except:\n",
        "    endpoint = \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze\"\n",
        "    username = \"apikey\"\n",
        "    password = \"yV0w0tQYFhAbgoJ0d-IMAtebL_5fdz-GRAvWzYb9bDa6-\"\n",
        "    parameters = {\n",
        "        'features': 'emotion,sentiment',\n",
        "        'version' : '2018-11-16',\n",
        "        'text': text,\n",
        "        'language' : 'en',\n",
        "    }\n",
        "    resp = requests.get(endpoint, params=parameters, auth=(username, password))\n",
        "    return resp.json()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr9aXNgsrnsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77ae703-5e1d-464a-aa69-0bfdd0495201"
      },
      "source": [
        "stock_input = input(\"Enter a stock:\")\n",
        "start_time_input = input(\"Enter a start date, a date no further than 7 days from the present(yr-mm-dd):\")\n",
        "end_time_input = input(\"Enter a end date, a date not less than the start date or past the present(yr-mm-dd):\")\n",
        "amountOfTweetsAndSubmissions = input(\"Enter a number of tweets/submissions:\")\n",
        "tweet_reddit_source_dict = {}\n",
        "tweet = search(stock_input, start_time_input, end_time_input, amountOfTweetsAndSubmissions)\n",
        "redditSub = reddit_data(stock_input, amountOfTweetsAndSubmissions)\n",
        "sent = []\n",
        "#stock_data = main(stock_input, start_time_input, end_time_input)\n",
        "stock_data = yfinance_data(stock_input, day_num)\n",
        "sent_avg_list = []\n",
        "stock_avg_diff_list = []\n",
        "sent_avg = 0\n",
        "for i in range(len(tweet)):\n",
        "  sentiment = getSentiment(tweet[i])\n",
        "  if isinstance(sentiment, int):\n",
        "    sent.append(sentiment)\n",
        "    sent_avg += sentiment\n",
        "  else:\n",
        "    sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "    sent.append(sentiment_score)\n",
        "    sent_avg += sentiment_score\n",
        "sent_avg = sent_avg / len(sent)\n",
        "\n",
        "sent_avg_redd = 0\n",
        "for i in range(len(redditSub)):\n",
        "  sentiment = getSentiment(redditSub[i])\n",
        "  if isinstance(sentiment, int):\n",
        "    sent.append(sentiment)\n",
        "    sent_avg_redd += sentiment\n",
        "  else:\n",
        "    sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "    sent.append(sentiment_score)\n",
        "    sent_avg_redd += sentiment_score\n",
        "sent_avg_redd = sent_avg_redd / len(sent)\n",
        "\n",
        "stock_avg_diff = 0\n",
        "for stock_diff in stock_data:\n",
        "  stock_avg_diff += stock_diff\n",
        "stock_avg_diff = stock_avg_diff / len(stock_data)\n",
        "tweet_reddit_source_dict[\"Twitter/Reddit Data\"] = tweet\n",
        "tweet_reddit_source_dict[\"Sentiment Compound Score\"] = sent\n",
        "tweetDataframe = pd.DataFrame(tweet_source_dict)\n",
        "if sent_avg > 0 and stock_avg_diff > 0:\n",
        "  print(\"Positive Correlation\") \n",
        "elif sent_avg < 0 and stock_avg_diff < 0:\n",
        "  print(\"Negative Correlation\") \n",
        "else:\n",
        "  print(\"No Correlation\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a stock:GME\n",
            "Enter a start date, a date no further than 7 days from the present(yr-mm-dd):2021-05-07\n",
            "Enter a end date, a date not less than the start date or past the present(yr-mm-dd):2021-05-08\n",
            "Enter a number of tweets:20\n",
            "No Correlation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pz2km0_LyOpm",
        "outputId": "0ff2cbc4-4d50-4d90-ea15-93f98c9c26a1"
      },
      "source": [
        "stocks_d = {\"Stocks\": [], \"Stock AVG Difference\": [], \"Sentiment\" : [] }\n",
        "stocks = pd.read_csv('Top100.csv', encoding=\"utf-8\", dtype=\"unicode\")\n",
        "stocks.drop(200, inplace=True)\n",
        "stocks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Name</th>\n",
              "      <th>Last</th>\n",
              "      <th>Change</th>\n",
              "      <th>%Chg</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMC</td>\n",
              "      <td>Amc Entertainment Holdings Inc</td>\n",
              "      <td>12.77</td>\n",
              "      <td>2.45</td>\n",
              "      <td>+23.74%</td>\n",
              "      <td>14.2</td>\n",
              "      <td>10.64</td>\n",
              "      <td>296524900</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NIO</td>\n",
              "      <td>Nio Inc</td>\n",
              "      <td>31.22</td>\n",
              "      <td>-2.46</td>\n",
              "      <td>-7.30%</td>\n",
              "      <td>34.27</td>\n",
              "      <td>30.71</td>\n",
              "      <td>113686700</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>Apple Inc</td>\n",
              "      <td>124.97</td>\n",
              "      <td>2.2</td>\n",
              "      <td>+1.79%</td>\n",
              "      <td>126.15</td>\n",
              "      <td>124.26</td>\n",
              "      <td>105861297</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PLTR</td>\n",
              "      <td>Palantir Technologies Inc Cl A</td>\n",
              "      <td>18.37</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-2.75%</td>\n",
              "      <td>19.47</td>\n",
              "      <td>17.82</td>\n",
              "      <td>87811600</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GE</td>\n",
              "      <td>General Electric Company</td>\n",
              "      <td>12.97</td>\n",
              "      <td>0.15</td>\n",
              "      <td>+1.17%</td>\n",
              "      <td>13.04</td>\n",
              "      <td>12.72</td>\n",
              "      <td>65582800</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>EXC</td>\n",
              "      <td>Exelon Corp</td>\n",
              "      <td>44.41</td>\n",
              "      <td>1.31</td>\n",
              "      <td>+3.03%</td>\n",
              "      <td>44.52</td>\n",
              "      <td>42.8</td>\n",
              "      <td>7353400</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>AZN</td>\n",
              "      <td>Astrazeneca Plc</td>\n",
              "      <td>55.05</td>\n",
              "      <td>0.55</td>\n",
              "      <td>+1.01%</td>\n",
              "      <td>55.22</td>\n",
              "      <td>54.43</td>\n",
              "      <td>7311700</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>DISCK</td>\n",
              "      <td>Discovery Comm Inc</td>\n",
              "      <td>30.56</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-1.51%</td>\n",
              "      <td>31.87</td>\n",
              "      <td>30.25</td>\n",
              "      <td>7295000</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>HL</td>\n",
              "      <td>Hecla Mining Company</td>\n",
              "      <td>7.13</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.97%</td>\n",
              "      <td>7.23</td>\n",
              "      <td>6.98</td>\n",
              "      <td>7278500</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>PYPL</td>\n",
              "      <td>Paypal Holdings</td>\n",
              "      <td>240.8</td>\n",
              "      <td>0.89</td>\n",
              "      <td>+0.37%</td>\n",
              "      <td>245.68</td>\n",
              "      <td>237.8</td>\n",
              "      <td>7274000</td>\n",
              "      <td>05/13/21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Symbol                            Name    Last  ...     Low     Volume      Time\n",
              "0      AMC  Amc Entertainment Holdings Inc   12.77  ...   10.64  296524900  05/13/21\n",
              "1      NIO                         Nio Inc   31.22  ...   30.71  113686700  05/13/21\n",
              "2     AAPL                       Apple Inc  124.97  ...  124.26  105861297  05/13/21\n",
              "3     PLTR  Palantir Technologies Inc Cl A   18.37  ...   17.82   87811600  05/13/21\n",
              "4       GE        General Electric Company   12.97  ...   12.72   65582800  05/13/21\n",
              "..     ...                             ...     ...  ...     ...        ...       ...\n",
              "195    EXC                     Exelon Corp   44.41  ...    42.8    7353400  05/13/21\n",
              "196    AZN                 Astrazeneca Plc   55.05  ...   54.43    7311700  05/13/21\n",
              "197  DISCK              Discovery Comm Inc   30.56  ...   30.25    7295000  05/13/21\n",
              "198     HL            Hecla Mining Company    7.13  ...    6.98    7278500  05/13/21\n",
              "199   PYPL                 Paypal Holdings   240.8  ...   237.8    7274000  05/13/21\n",
              "\n",
              "[200 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "SRVsELYo1lKw",
        "outputId": "17c806b3-c3e5-4d62-82de-893c5b468915"
      },
      "source": [
        "for i in range(len(stocks[\"Symbol\"])):\n",
        "  tweet_input = stocks[\"Name\"][i]\n",
        "  stock_input = stocks[\"Symbol\"][i]\n",
        "  start_time_input = \"2021-05-6\"\n",
        "  end_time_input = \"2021-05-12\"\n",
        "  day_num = int(end_time_input[-1]) - int(start_time_input[-1]) \n",
        "  amountOfTweets = 500\n",
        "  tweet_source_dict = {}\n",
        "  try:\n",
        "    tweet = search(tweet_input, start_time_input, end_time_input, amountOfTweets)\n",
        "  except:\n",
        "    tweet = None\n",
        "  try:\n",
        "    reddit = reddit_data(stock_input, day_num)\n",
        "  except:\n",
        "    reddit = None\n",
        "  #stock_data = main(stock_input, start_time_input, end_time_input)\n",
        "  stock_data = yfinance_data(stock_input, day_num)\n",
        "  ibm_sent = []\n",
        "  ibm_sent_2 = []\n",
        "  stock_sent_avg_dict = {}\n",
        "  ibm_sent_avg_list = []\n",
        "  ibm_sent_avg_2_list = []\n",
        "  stock_avg_diff_list = []\n",
        "  ibm_sent_avg = 0\n",
        "  ibm_sent_avg_2 = 0\n",
        "  total_avg = 0\n",
        "  if tweet != None and reddit != None:\n",
        "    for i in range(len(tweet)):\n",
        "      sentiment = getSentiment(tweet[i])\n",
        "      sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "      ibm_sent.append(sentiment_score)\n",
        "      ibm_sent_avg += sentiment_score\n",
        "    ibm_sent_avg = ibm_sent_avg / len(ibm_sent)\n",
        "    for i in range(len(reddit)):\n",
        "      sentiment = getSentiment(reddit[i])\n",
        "      sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "      ibm_sent_2.append(sentiment_score)\n",
        "      ibm_sent_avg_2 += sentiment_score\n",
        "    ibm_sent_avg_2 = ibm_sent_avg_2 / len(ibm_sent_2)\n",
        "    total_avg = (ibm_sent_avg + ibm_sent_avg_2) / 2\n",
        "    stocks_d[\"Sentiment\"].append(total_avg)\n",
        "    stock_avg_diff = 0\n",
        "    for stock_diff in stock_data:\n",
        "      stock_avg_diff += stock_diff\n",
        "    stock_avg_diff = stock_avg_diff / len(stock_data)\n",
        "    stocks_d[\"Stock AVG Difference\"].append(stock_avg_diff)\n",
        "    stocks_d[\"Stocks\"].append(stocks[\"Symbol\"][i])  \n",
        "  elif tweet != None or reddit != None: \n",
        "    if tweet != None:\n",
        "      for i in range(len(tweet)):\n",
        "        sentiment = getSentiment(tweet[i])\n",
        "        sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "        ibm_sent.append(sentiment_score)\n",
        "        ibm_sent_avg += sentiment_score\n",
        "      ibm_sent_avg = ibm_sent_avg / len(ibm_sent)\n",
        "      stocks_d[\"Sentiment\"].append(ibm_sent_avg)\n",
        "      stock_avg_diff = 0\n",
        "      for stock_diff in stock_data:\n",
        "        stock_avg_diff += stock_diff\n",
        "      stock_avg_diff = stock_avg_diff / len(stock_data)\n",
        "      stocks_d[\"Stock AVG Difference\"].append(stock_avg_diff)\n",
        "      stocks_d[\"Stocks\"].append(stocks[\"Symbol\"][i])\n",
        "    elif reddit != None:\n",
        "      for i in range(len(reddit)):\n",
        "        sentiment = getSentiment(reddit[i])\n",
        "        sentiment_score = sentiment[\"sentiment\"][\"document\"][\"score\"]\n",
        "        ibm_sent_2.append(sentiment_score)\n",
        "        ibm_sent_avg_2 += sentiment_score\n",
        "      ibm_sent_avg_2 = ibm_sent_avg_2 / len(ibm_sent_2)\n",
        "      stocks_d[\"Sentiment\"].append(ibm_sent_avg_2) \n",
        "      for stock_diff in stock_data:\n",
        "        stock_avg_diff += stock_diff\n",
        "      stock_avg_diff = stock_avg_diff / len(stock_data)\n",
        "      stocks_d[\"Stock AVG Difference\"].append(stock_avg_diff)\n",
        "      stocks_d[\"Stocks\"].append(stocks[\"Symbol\"][i])  \n",
        "  else:\n",
        "      stocks_d[\"Sentiment\"].append(None) \n",
        "      stock_avg_diff = 0\n",
        "      for stock_diff in stock_data:\n",
        "        stock_avg_diff += stock_diff\n",
        "      if len(stock_data) == 0:\n",
        "        stock_avg_diff = None\n",
        "      else:\n",
        "        stock_avg_diff = stock_avg_diff / len(stock_data)\n",
        "      stocks_d[\"Stock AVG Difference\"].append(stock_avg_diff)\n",
        "      stocks_d[\"Stocks\"].append(stocks[\"Symbol\"][i]) \n",
        "print(len(stocks_d[\"Stocks\"]))\n",
        "print(len(stocks_d[\"Sentiment\"]))\n",
        "print(len(stocks_d[\"Stock AVG Difference\"]))\n",
        "stocks_df = pd.DataFrame(stocks_d)\n",
        "print(stocks_df)\n",
        "#stocks_df.to_sql(\"StockSentimentData\", con=engine, if_exists='replace', index = False, chunksize=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- PBR.A: No data found, symbol may be delisted\n",
            "- DOWNLOADED FROM BARCHART.COM AS OF 05-13-2021 11:40PM CDT: No data found, symbol may be delisted\n",
            "270\n",
            "271\n",
            "270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1048d62f01b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Stock AVG Difference\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mstocks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#stocks_df.to_sql(\"StockSentimentData\", con=engine, if_exists='replace', index = False, chunksize=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkuoW1UEaKHb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqbzMzfbIWpC"
      },
      "source": [
        "!pip install pandas sklearn matplotlib\n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"nyse-listed_csv.csv\")\n",
        "print('Raw data from New York Stock Exchange')\n",
        "print(data.head())\n",
        "data = data.drop('Date',axis=1) \n",
        "data = data.drop('Adj Close',axis = 1)\n",
        "print('\\n\\nData after removing Date and Adj Close : ')\n",
        "print(data.head())\n",
        "data_X = data.loc[:,data.columns !=  'Close' ]\n",
        "data_Y = data['Close']\n",
        "train_X, test_X, train_y,test_y = train_test_split(data_X,data_Y,test_size=0.25)\n",
        "print('\\n\\nTraining Set')\n",
        "print(train_X.head())\n",
        "print(train_y.head())\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(train_X,train_y)\n",
        "predict_y = regressor.predict(test_X)\n",
        "print('Prediction Score : ' , regressor.score(test_X,test_y))\n",
        "error = mean_squared_error(test_y,predict_y)\n",
        "print('Mean Squared Error : ',error)\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.grid()\n",
        "ax.set(xlabel='Close ($)',ylabel='Open ($)', title='Tesla Stock Prediction using Linear Regression')\n",
        "ax.plot(test_X['Open'],test_y)\n",
        "ax.plot(test_X['Open'],predict_y)\n",
        "fig.savefig('LRPlot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46kFKLMaZCsx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}